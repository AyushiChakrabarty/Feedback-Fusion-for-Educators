{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-processing of CSV files"
      ],
      "metadata": {
        "id": "JVVMBm24TcF2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3ABMm5PbtP0",
        "outputId": "583c8f6f-96df-4268-a89b-b12718797d6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded data_file_1_02.csv with encoding ISO-8859-1. Shape: (1279, 4)\n",
            "Successfully loaded data_file_2_08.csv with encoding ISO-8859-1. Shape: (718, 4)\n",
            "Successfully loaded data_file_3_08.csv with encoding ISO-8859-1. Shape: (621, 4)\n",
            "Combined DataFrame shape: (2618, 4)\n",
            "DataFrame shape before dropping NaNs: (2618, 4)\n",
            "DataFrame shape after dropping NaNs: (1324, 4)\n",
            "Final DataFrame shape: (1324, 4)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "\n",
        "def load_data(file_paths, encodings=['utf-8', 'ISO-8859-1']):\n",
        "    dataframes = []\n",
        "    for file_path in file_paths:\n",
        "        for encoding in encodings:\n",
        "            try:\n",
        "                df = pd.read_csv(file_path, encoding=encoding)\n",
        "                dataframes.append(df)\n",
        "                print(f\"Successfully loaded {file_path} with encoding {encoding}. Shape: {df.shape}\")\n",
        "                break  # Exit the loop if reading is successful\n",
        "            except UnicodeDecodeError:\n",
        "                continue  # Try the next encoding if there's an error\n",
        "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
        "    print(f\"Combined DataFrame shape: {combined_df.shape}\")\n",
        "    return combined_df\n",
        "\n",
        "def clean_text(text):\n",
        "    if pd.isnull(text):\n",
        "        return ''\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
        "    text = re.sub(f'[{re.escape(string.punctuation)}]', '', text)  # Remove punctuation\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)  # Remove non-ASCII characters\n",
        "    return text.strip()\n",
        "\n",
        "def preprocess_dataframe(df):\n",
        "    print(f\"DataFrame shape before dropping NaNs: {df.shape}\")\n",
        "    df.dropna(inplace=True)  # Remove empty rows\n",
        "    print(f\"DataFrame shape after dropping NaNs: {df.shape}\")\n",
        "    df['concerns'] = df['concerns'].apply(clean_text)\n",
        "    df['anything else'] = df['anything else'].apply(clean_text)\n",
        "    return df\n",
        "\n",
        "file_paths = ['data_file_1_02.csv', 'data_file_2_08.csv', 'data_file_3_08.csv']\n",
        "df = load_data(file_paths)\n",
        "df = preprocess_dataframe(df)\n",
        "\n",
        "# Encode labels\n",
        "label_mapping = {'AC': 0, 'PC': 1, 'TC': 2, 'NC': 3}\n",
        "df['concerns category'] = df['concerns category'].map(label_mapping)\n",
        "df['anything else category'] = df['anything else category'].map(label_mapping)\n",
        "\n",
        "# Create combined text and category columns\n",
        "concerns_df = df[['concerns', 'concerns category']].rename(columns={'concerns': 'combined_text', 'concerns category': 'combined_category'})\n",
        "anything_else_df = df[['anything else', 'anything else category']].rename(columns={'anything else': 'combined_text', 'anything else category': 'combined_category'})\n",
        "\n",
        "# Concatenate both dataframes\n",
        "final_df = pd.concat([concerns_df, anything_else_df], ignore_index=True)\n",
        "\n",
        "# Save the final cleaned dataset\n",
        "final_df.to_csv('cleaned_data.csv', index=False)\n",
        "\n",
        "print(f\"Final DataFrame shape: {df.shape}\")"
      ]
    }
  ]
}