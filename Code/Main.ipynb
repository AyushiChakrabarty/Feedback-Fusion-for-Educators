{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Code.build_prompt import build_examples_prompt\n",
    "from Code.utils import read_list_from_file, df_from_file, multiple_df\n",
    "from Code.pretrained_model import load_model_and_tokenizer, predict_with_loaded_model, predict_column, calculate_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from torch.nn.functional import softmax\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from transformers import TFAutoModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Data/Merged_file.csv\")\n",
    "\n",
    "# Define category mapping\n",
    "category_mapping = {0: 'AC', 1: \"PC\", 2: \"TC\", 3: \"NC\"}\n",
    "\n",
    "# Convert 'concerns category' and 'anything else category' to numerical values\n",
    "df['ground_truth_concerns'] = df['concerns category'].map({v: k for k, v in category_mapping.items()})\n",
    "df['ground_truth_anything_else'] = df['anything else category'].map({v: k for k, v in category_mapping.items()})\n",
    "\n",
    "# Check for and handle NaN values in the ground truth columns\n",
    "df['ground_truth_concerns'] = df['ground_truth_concerns'].fillna(-1).astype(int)\n",
    "df['ground_truth_anything_else'] = df['ground_truth_anything_else'].fillna(-1).astype(int)\n",
    "\n",
    "# Predict categories for the 'concerns' column\n",
    "df = predict_column(df, category_mapping, \"concerns\")\n",
    "\n",
    "# Predict categories for the 'anything else' column\n",
    "df = predict_column(df, category_mapping, \"anything else\")\n",
    "\n",
    "# Calculate accuracy if ground truth is available\n",
    "accuracy_concerns = calculate_accuracy(df, \"concerns\", \"ground_truth_concerns\")\n",
    "accuracy_anything_else = calculate_accuracy(df, \"anything else\", \"ground_truth_anything_else\")\n",
    "\n",
    "# Print accuracy results\n",
    "print(f\"Accuracy for 'concerns': {accuracy_concerns}\")\n",
    "print(f\"Accuracy for 'anything else': {accuracy_anything_else}\")\n",
    "\n",
    "# Save the results to an Excel file\n",
    "path = 'result_testDataLabeled.xlsx'\n",
    "df.to_excel(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ret = multiple_df([\"ac.txt\", \"timeManagement.txt\", \"OTHER.txt\", \"LM.txt\"])\n",
    "ret = multiple_df([\"AC.txt\", \"PC.txt\", \"TC.txt\", \"NC.txt\"])\n",
    "shuffled_df = ret.sample(frac=1).reset_index(drop=True)\n",
    "shuffled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads my tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "#Loads my data frame\n",
    "df = shuffled_df\n",
    "\n",
    "#Puts my data frame in a good format for ML\n",
    "#Max length is 512\n",
    "#encoded_data = tokenizer(df['response'].tolist(), padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "#labels = torch.tensor(df['category'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your DataFrame\n",
    "df = shuffled_df\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize text and encode labels\n",
    "encoded_data = tokenizer(df['response'].tolist(), padding=True, truncation=True, max_length=128, return_tensors='pt')  # Reduced max_length for speed\n",
    "labels = torch.tensor(df['category_int'].tolist())\n",
    "\n",
    "# Train-Test Split\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(encoded_data['input_ids'],\n",
    "                                                                     labels,\n",
    "                                                                     test_size=0.2,\n",
    "                                                                     random_state=42)\n",
    "\n",
    "# Create DataLoader for training\n",
    "train_dataset = TensorDataset(train_texts, train_labels)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "\n",
    "# Create DataLoader for testing\n",
    "test_dataset = TensorDataset(test_texts, test_labels)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "\n",
    "# Load pre-trained BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(df['category_int'].unique()))\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    epoch_loss = 0\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        inputs, labels = batch\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_epoch_loss = epoch_loss / len(train_dataloader)\n",
    "    print(f\"Average Epoch Loss: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "# Evaluation loop (optional)\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        inputs, labels = batch\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(input_ids=inputs)\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "torch.save(model.state_dict(), 'bert_model.pth')\n",
    "\n",
    "# Load the model from the file\n",
    "loaded_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=4)\n",
    "loaded_model.load_state_dict(torch.load('bert_model.pth'))\n",
    "loaded_model.eval()  # Set the model to evaluation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text for evaluation\n",
    "text = \"I'm concerned about not remembering stuff from calc\"\n",
    "\n",
    "# Tokenize and encode the text\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "# Forward pass through the model\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Get predicted probabilities (you may need to adjust this based on your specific task)\n",
    "probs = softmax(outputs.logits, dim=1)\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class = torch.argmax(probs, dim=1).item()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "print(f\"Class probabilities: {probs.tolist()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_Summer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
